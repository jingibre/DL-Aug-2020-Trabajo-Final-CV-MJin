{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCY6UbkkI9_N"
   },
   "source": [
    "# Style Transfer\n",
    "\n",
    "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
    "\n",
    "La idea de este trabajo final es reproducir el siguiente paper:\n",
    "\n",
    "https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
    "\n",
    "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
    "\n",
    "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
    "\n",
    "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
    "\n",
    "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
    "\n",
    "A este procedimiento se lo denomina neural style transfer.\n",
    "\n",
    "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
    "\n",
    "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
    "\n",
    "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBgrqie3mcUC",
    "outputId": "0b03da80-249a-4ee7-abc2-3c1aae322ebc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!mkdir /content/output\\n!git clone https://github.com/jingibre/DL-Aug-2020-Trabajo-Final-CV-MJin.git\\n%cd DL-Aug-2020-Trabajo-Final-CV-MJin\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el directorio para los archivos de salida\n",
    "\n",
    "# Si se corre en Colab, correr las lines de abajo.\n",
    "'''\n",
    "!mkdir /content/output\n",
    "!git clone https://github.com/jingibre/DL-Aug-2020-Trabajo-Final-CV-MJin.git\n",
    "%cd DL-Aug-2020-Trabajo-Final-CV-MJin\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NIxH20o2eFoc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iLkV1bnFl_tK"
   },
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "\n",
    "# Descomentar esta linea para usar las imagenes por defecto originales\n",
    "'''\n",
    "base_image_path = Path(\"original source images/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "style_reference_image_path = Path(\"original source images/La_noche_estrellada1.jpg\")\n",
    "'''\n",
    "\n",
    "# Descomentar esta linea para obtener la combinación de El Colo y La pintura de Van Gogh\n",
    "\n",
    "base_image_path = Path(\"source images/colo_1.jpeg\")\n",
    "style_reference_image_path = Path(\"source images/van_2.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "# Descomentar esta linea para obtener la combinación de El Verdadero Van Gogh y La pintua de Van Gogh\n",
    "'''\n",
    "base_image_path = Path(\"source images/real_van.jpg\")\n",
    "style_reference_image_path = Path(\"source images/van_2.jpg\")\n",
    "'''\n",
    "\n",
    "result_prefix = Path(\"content/output\")\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz2PeGfpeYzj"
   },
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "- total_variation_weight: Este parámetro pesa/pondera el valor que se entrega a la loss de suavizado de la imagen (explicada en la respuesta 5) frente a las losses de estilo y contenido. Esta loss no se encuentra definida en el paper.\n",
    "\n",
    "- style_weight & content_weight: Son los pesos/ponderación del estilo y contenido respectivamente. Haciendo referencia al trabajo, *content_weight* sería $\\alpha$ y *style_weight* sería $\\beta$. Estos parámetros ponderan las losses regulando asi la importancia que se le da a cada característica a la hora de generar la nueva imagen (que combina estilo y contenido).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P9Dt3aaEmJWS"
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 0.1\n",
    "style_weight = 100\n",
    "content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CQQJOhCVuse6"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg2ct-8agm1E"
   },
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "\n",
    "Ayuda: https://keras.io/applications/\n",
    "\n",
    "Respuesta: \n",
    "- La función detallada en la siguiente celda prepara la imagen para ser introducida en la red CNN VGG19. En principio la carga y luego la convierte en un array 3D (primeras dos lineas). \n",
    "- Luego, sabiendo que el input de la VGG es (batch_size, image_width, image_height, image_channels), se le debe agregar la dimension de batch_size, y esa justamente es la linea de expand. \n",
    "- Por último, el paso de pre_process, es un step requerido por la arquitectura de la red. En el caso de VGG19, se convierte a la imagen de RGB en BGR, donde se centra cada color de la imagen, con respecto a la media del dataset de ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tAkljg4zuzYd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTf0YDSagt10"
   },
   "source": [
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "Respuesta: \n",
    "- Sabiendo que lo que hace el pre_process es restarle/centrar todos los canales RGB con respecto de las medias de ImageNet, también sabemos que el resultado de la imagen que generemos estará centrada en esas medias. Por esa razón, para volver a tener una imagen \"real\" o RGB, lo que hay que hacer, es simplemente de-centrar/sumarle el el valor de las medias a cada canal de la imagen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "y5LaTrsAu14z"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HYNio09mu4S3"
   },
   "outputs": [],
   "source": [
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a1Lbw02Uu--o"
   },
   "outputs": [],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJEi0YI3Uzrm"
   },
   "source": [
    "Aclaración:\n",
    "\n",
    "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gGO_jGFfvEbF"
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdG59VRavHGB",
    "outputId": "f6fa9e19-c529-41d2-e61f-e58a582ef475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70-vs_jZkKVc"
   },
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "> La matriz de Gram contiene/computa la correlación de _features_ que existe entre filtros de una misma capa, esto actúa como una definición de _estilo_. Esta matriz es la clave para entregarle a la imagen generada el estilo deseado (la generada debe tener la misma matriz de Gram que aquella que se desea copiar el estilo). A nivel modelo, esta matriz es el la que se utiliza en la Loss de estilo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- ¿Por qué se permutan las dimensiones de x?\n",
    "> Se permutan las dimensiones, para llevar la dimension de canales [2] (RGB, o BGR en realidad siendo VGG) a la primer dimension, y así, al aplicar el flatten me genere 3 tensores, uno para cada canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K1FODPATvJ1k"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBQkKFY0Rbx-"
   },
   "source": [
    "# 5) Losses:\n",
    "\n",
    "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "Rta:\n",
    "- La _style_loss_ mide la diferencia que existe entre el estilo (o matriz de Gram) de la imagen semilla vs el estilo de la imagen generada (que combina estilo de la semilla y contenido de otra).\n",
    "\n",
    "- La _content_loss_ evalúa la diferencia entre features de una layer para la imagen de contenido semilla (base) y aquellos de la imagen generada (combination). En otras palabras, evalúa la diferencia de contenido que hay entre la imagen de referencia y la generada.\n",
    "\n",
    "- La _total_variation_loss mide la diferencia que hay entre pixeles adyacentes, esta loss al ser minimizada, actúa entonces, como una suavizadora de cambios en la imagen / ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1-Gt0ahWvN6q"
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XCqnju5RvQCo"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "udEp5h31vRnY"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-65vcinbvTZ0"
   },
   "outputs": [],
   "source": [
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pbz4n1OhvV2K"
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JbydbOaVcvU"
   },
   "source": [
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "\n",
    "\n",
    "- _def eval_loss_and_grads(x)_: Esta función devuelve el valor de los gradientes y de la Loss para una determinada imagen combinada generada.  \n",
    "\n",
    "- _class Evaluator_: Está clase/objeto se encarga justamente de evaluar/contener las losses y gradientes durante el proceso de optimizado. Hace uso, claramente, la función definida arriba.\n",
    "\n",
    "- _fmin_l_bfgs_b_: Esta función es la que se encarga de minimizar la Loss que fue definida arriba. Este algoritmo de minimización difiere de los utilizados en el curso hasta ahora ya que es de _segundo orden_. Esto quiere decir que usan la matriz Heassiana o alguna aproximación de la misma para tomar en cuenta la curvatura (no solamente la pendiente) de la función objetivo. L-BFGS es un metodo de segundo orden y tiene la ventaja además de utilizar menos memoria que otros métodos de optimización de este estilo.\n",
    "\n",
    "\n",
    "\n",
    "La implementación presentada en el código presenta algunas diferencias con el paper:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.   El termino de la loss asociado a total_variation no se encuentra descrito en el paper donde solamente se asigna un termino para estilo y otro para contenido. No obstante, su adición mejora el resultado del código ya que suaviza satisfactoriamente el ruido en las imágenes.\n",
    "\n",
    "2.   En el paper indica que cambiar las operaciones de max-pooling for aquellas de average pooling mejora el flujo del gradiente. Sin embargo, en esta implementación estás capas no se ven modificadas en el _model_ dejando así max-pooling en las capas de down sampling.\n",
    "\n",
    "3.   Por último, la layer elegida para la reconstrucción del contenido difiere levemente de la mencionada en el paper, siendo el bloque 5 el elegido y no el 4 como indica el documento. Esta última diferencia no resulta crucial, y tampoco los autores indicaban que el bloque 4 de la conv 2 fuese el único posible.  De hecho, solo mencionan que la elección de capas menores reconstruyen a la perfección la imagen, y aquellas más profundas preservan unicamente información de alto orden.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zVE1_qemvZeN"
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Qbl9roIgvdb1"
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb0yOEl-WOE6"
   },
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n31YBwCVvhAI",
    "outputId": "67c731d5-7f57-41ba-fefc-eb25719db0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 10360911000000.0\n",
      "Image saved as content\\output\\output_at_iteration_0.png\n",
      "Iteration 0 completed in 78s\n",
      "Start of iteration 1\n",
      "Current loss value: 4097847600000.0\n",
      "Image saved as content\\output\\output_at_iteration_1.png\n",
      "Iteration 1 completed in 79s\n",
      "Start of iteration 2\n",
      "Current loss value: 2189774800000.0\n",
      "Image saved as content\\output\\output_at_iteration_2.png\n",
      "Iteration 2 completed in 77s\n",
      "Start of iteration 3\n",
      "Current loss value: 1462199600000.0\n",
      "Image saved as content\\output\\output_at_iteration_3.png\n",
      "Iteration 3 completed in 79s\n",
      "Start of iteration 4\n",
      "Current loss value: 1056361300000.0\n",
      "Image saved as content\\output\\output_at_iteration_4.png\n",
      "Iteration 4 completed in 78s\n",
      "Start of iteration 5\n",
      "Current loss value: 757222200000.0\n",
      "Image saved as content\\output\\output_at_iteration_5.png\n",
      "Iteration 5 completed in 78s\n",
      "Start of iteration 6\n",
      "Current loss value: 603718100000.0\n",
      "Image saved as content\\output\\output_at_iteration_6.png\n",
      "Iteration 6 completed in 84s\n",
      "Start of iteration 7\n",
      "Current loss value: 510647200000.0\n",
      "Image saved as content\\output\\output_at_iteration_7.png\n",
      "Iteration 7 completed in 91s\n",
      "Start of iteration 8\n",
      "Current loss value: 436575300000.0\n",
      "Image saved as content\\output\\output_at_iteration_8.png\n",
      "Iteration 8 completed in 97s\n",
      "Start of iteration 9\n",
      "Current loss value: 387054800000.0\n",
      "Image saved as content\\output\\output_at_iteration_9.png\n",
      "Iteration 9 completed in 95s\n",
      "Start of iteration 10\n",
      "Current loss value: 327863170000.0\n",
      "Image saved as content\\output\\output_at_iteration_10.png\n",
      "Iteration 10 completed in 96s\n",
      "Start of iteration 11\n",
      "Current loss value: 296304080000.0\n",
      "Image saved as content\\output\\output_at_iteration_11.png\n",
      "Iteration 11 completed in 79s\n",
      "Start of iteration 12\n",
      "Current loss value: 273469820000.0\n",
      "Image saved as content\\output\\output_at_iteration_12.png\n",
      "Iteration 12 completed in 81s\n",
      "Start of iteration 13\n",
      "Current loss value: 253587000000.0\n",
      "Image saved as content\\output\\output_at_iteration_13.png\n",
      "Iteration 13 completed in 82s\n",
      "Start of iteration 14\n",
      "Current loss value: 240025750000.0\n",
      "Image saved as content\\output\\output_at_iteration_14.png\n",
      "Iteration 14 completed in 80s\n",
      "Start of iteration 15\n",
      "Current loss value: 227332000000.0\n",
      "Image saved as content\\output\\output_at_iteration_15.png\n",
      "Iteration 15 completed in 80s\n",
      "Start of iteration 16\n",
      "Current loss value: 218356000000.0\n",
      "Image saved as content\\output\\output_at_iteration_16.png\n",
      "Iteration 16 completed in 76s\n",
      "Start of iteration 17\n",
      "Current loss value: 205970330000.0\n",
      "Image saved as content\\output\\output_at_iteration_17.png\n",
      "Iteration 17 completed in 76s\n",
      "Start of iteration 18\n",
      "Current loss value: 195519230000.0\n",
      "Image saved as content\\output\\output_at_iteration_18.png\n",
      "Iteration 18 completed in 79s\n",
      "Start of iteration 19\n",
      "Current loss value: 188423100000.0\n",
      "Image saved as content\\output\\output_at_iteration_19.png\n",
      "Iteration 19 completed in 81s\n",
      "Start of iteration 20\n",
      "Current loss value: 182764670000.0\n",
      "Image saved as content\\output\\output_at_iteration_20.png\n",
      "Iteration 20 completed in 79s\n",
      "Start of iteration 21\n",
      "Current loss value: 176731010000.0\n",
      "Image saved as content\\output\\output_at_iteration_21.png\n",
      "Iteration 21 completed in 80s\n",
      "Start of iteration 22\n",
      "Current loss value: 171811650000.0\n",
      "Image saved as content\\output\\output_at_iteration_22.png\n",
      "Iteration 22 completed in 80s\n",
      "Start of iteration 23\n",
      "Current loss value: 166236420000.0\n",
      "Image saved as content\\output\\output_at_iteration_23.png\n",
      "Iteration 23 completed in 87s\n",
      "Start of iteration 24\n",
      "Current loss value: 161917000000.0\n",
      "Image saved as content\\output\\output_at_iteration_24.png\n",
      "Iteration 24 completed in 80s\n",
      "Start of iteration 25\n",
      "Current loss value: 158518350000.0\n",
      "Image saved as content\\output\\output_at_iteration_25.png\n",
      "Iteration 25 completed in 81s\n",
      "Start of iteration 26\n",
      "Current loss value: 154883110000.0\n",
      "Image saved as content\\output\\output_at_iteration_26.png\n",
      "Iteration 26 completed in 79s\n",
      "Start of iteration 27\n",
      "Current loss value: 150343140000.0\n",
      "Image saved as content\\output\\output_at_iteration_27.png\n",
      "Iteration 27 completed in 81s\n",
      "Start of iteration 28\n",
      "Current loss value: 146019430000.0\n",
      "Image saved as content\\output\\output_at_iteration_28.png\n",
      "Iteration 28 completed in 77s\n",
      "Start of iteration 29\n",
      "Current loss value: 141100300000.0\n",
      "Image saved as content\\output\\output_at_iteration_29.png\n",
      "Iteration 29 completed in 82s\n",
      "Start of iteration 30\n",
      "Current loss value: 136868954000.0\n",
      "Image saved as content\\output\\output_at_iteration_30.png\n",
      "Iteration 30 completed in 82s\n",
      "Start of iteration 31\n",
      "Current loss value: 134328410000.0\n",
      "Image saved as content\\output\\output_at_iteration_31.png\n",
      "Iteration 31 completed in 82s\n",
      "Start of iteration 32\n",
      "Current loss value: 132023510000.0\n",
      "Image saved as content\\output\\output_at_iteration_32.png\n",
      "Iteration 32 completed in 84s\n",
      "Start of iteration 33\n",
      "Current loss value: 130199855000.0\n",
      "Image saved as content\\output\\output_at_iteration_33.png\n",
      "Iteration 33 completed in 82s\n",
      "Start of iteration 34\n",
      "Current loss value: 128194530000.0\n",
      "Image saved as content\\output\\output_at_iteration_34.png\n",
      "Iteration 34 completed in 84s\n",
      "Start of iteration 35\n",
      "Current loss value: 126125600000.0\n",
      "Image saved as content\\output\\output_at_iteration_35.png\n",
      "Iteration 35 completed in 79s\n",
      "Start of iteration 36\n",
      "Current loss value: 123959484000.0\n",
      "Image saved as content\\output\\output_at_iteration_36.png\n",
      "Iteration 36 completed in 78s\n",
      "Start of iteration 37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-c5e1a2324884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start of iteration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n\u001b[0m\u001b[0;32m     11\u001b[0m                                      fprime=evaluator.grads, maxfun=20)\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current loss value:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    195\u001b[0m             'maxls': maxls}\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0m\u001b[0;32m    198\u001b[0m                            **opts)\n\u001b[0;32m    199\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-c0eccc4316a2>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_loss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-a5e92c09b58a>\u001b[0m in \u001b[0;36meval_loss_and_grads\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_loss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_nrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_ncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkiJtofbWWy1"
   },
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "### _Variacion del content / style ratio_\n",
    "\n",
    "<img src=\"https://github.com/jingibre/DL-Aug-2020-Trabajo-Final-CV-MJin/blob/74c64ee0fe1bacbf60b762bb62bcdc4662482bcc/output%20images/original_style_weight_comparisson.png?raw=true\">\n",
    "\n",
    "- Con el fin de aislar únicamente la competencia entre estilo y contenido, se deja fijo al peso de la Loss suavizadora en 0.1. \n",
    "- Luego, se procede a correr el modelo con las imagenes originales presentadas variando el ratio $\\alpha$ / $\\beta$ (contenido / estilo) en 1 - 0.1 - 0.001.\n",
    "- En la figura presentada arriba se puede ver como a medida que se aumenta el peso del estilo (o decrece el ratio), la información del contenido comienza a perderse. Esto es particularmente notable en las zonas resaltadas donde se ve como progresivamente disminuye definición de los edificios.\n",
    "\n",
    "### _Variación de total_variation_weight_\n",
    "\n",
    "<img src=\"https://github.com/jingibre/DL-Aug-2020-Trabajo-Final-CV-MJin/blob/main/output%20images/comparison%20variational.png?raw=true\">\n",
    "\n",
    "- En este caso, con el fin de aislar y entender el efecto de la nueva loss, se deja fijo el ratio de estilo y contenido en 0.1 ($\\alpha = 1$ y $\\beta = 10$).\n",
    "- Luego, se procede a correr el modelo con las imagenes originales variando el peso del _total_variation_weight_ en 0 - 0.1 - 1.\n",
    "- En la figura presentada, se ve como en la imagen que no posee termino suavizador (_total_variation_weight_ = 0) existen zonas de ruido o variaciones fuertes en la generación de la imagen. Por el contrario, en aquellas imagenes donde el termino de _total variation_ esta presente, las zonas poseen menos ruido, suavizando  la imagen y generando un output más continuo. Aún así, es importante destacar que una elevada ponderación de dicho termino puede llevar a una sobre suavización donde se pierdan muchas estructuras finas o detalladas de la imagen.\n",
    "\n",
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "### _Van Gogh y El Colo_\n",
    "\n",
    "<img src=\"https://github.com/jingibre/DL-Aug-2020-Trabajo-Final-CV-MJin/blob/main/output%20images/colo_combinada.png?raw=true\">\n",
    "\n",
    "Al ser Van Gogh uno de mis artista preferidos, elegirlo para el trabajo fue una decisión natural. Por otro lado, la selección de contenido, inicialmente, resultó más compleja ya que me aparentaba poco innovador elegir un paisaje (que de esos ya el artista posee muchos). Por eso, pensando en el siguiente razonamiento: \n",
    "- Si bien el estilo es separado del contenido al generarse el modelo, este estilo termina de alguna manera heredando ciertos aspectos del contenido de su imagen semilla (ejemplo, las estrellas de la noche estrellada que aparecen en las primeras imagenes aunque no haya ninguna en el cielo de la imagen de contenido).\n",
    "Se eligió usar entonces, como imagen de contenido a una persona cercana que se parecía a Van Gogh y ver que tan bien actuaba el modelo encima de una foto de el. Vemos como en este caso, el modelo ofrece una buena performance dando una buena ilusión de que la imagen generada es de hecho un cuadro del artista.\n",
    "\n",
    "\n",
    "### _Van Gogh y Van Gogh_\n",
    "\n",
    "<img src=\"https://github.com/jingibre/DL-Aug-2020-Trabajo-Final-CV-MJin/blob/74c64ee0fe1bacbf60b762bb62bcdc4662482bcc/output%20images/van_gogh_combinada.png?raw=truee\">\n",
    "\n",
    "Con esta idea en mente y viendo su buena performance, se optó por llevar un paso más allá la idea. En este caso, se utiliza una foto \"real\" del artista y se le aplica un estilo de su propio auto retrato. En este caso se tiene la ventaja de tenemos un indicador directo de la performance de nuestro modelo, en cuanto mejor sea, más debería parecerse la imagen generada a la pintura original. Vemos como, efectivamente el desempeño del modelo es satisfactorio generando una imagen sorprendemente similar a la imagen original.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Trabajo_Final_CNN_Style_Transfer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
